{
    "sourceFile": "Documentation/02_Developer_Guide/05_Processing_Pipeline.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1745494656395,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1745507051012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,10 +7,11 @@\n 1.  **Workspace Setup (`_setup_workspace`)**:\r\n     *   Creates a temporary directory using `tempfile.mkdtemp()` to isolate the processing of the current asset.\r\n \r\n 2.  **Input Extraction (`_extract_input`)**:\r\n-    *   If the input is a ZIP archive, it's extracted into the temporary workspace.\r\n+    *   If the input is a supported archive type (.zip, .rar, .7z), it's extracted into the temporary workspace using the appropriate library (`zipfile`, `rarfile`, or `py7zr`).\r\n     *   If the input is a directory, its contents are copied into the temporary workspace.\r\n+    *   Includes basic error handling for invalid or password-protected archives.\r\n \r\n 3.  **File Inventory and Classification (`_inventory_and_classify_files`)**:\r\n     *   Scans the contents of the temporary workspace.\r\n     *   Uses the pre-compiled regex patterns from the loaded `Configuration` object to classify each file.\r\n"
                },
                {
                    "date": 1745934434181,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,5 +76,7 @@\n 10. **Workspace Cleanup (`_cleanup_workspace`)**:\r\n     *   Removes the temporary workspace directory and its contents using `shutil.rmtree()`. This is called within a `finally` block to ensure cleanup is attempted even if errors occur during processing.\r\n \r\n 11. **(Optional) Blender Script Execution**:\r\n-    *   If triggered via CLI arguments (`--nodegroup-blend`, `--materials-blend`) or GUI controls, the orchestrator (`main.py` or `gui/processing_handler.py`) executes the corresponding Blender scripts (`blenderscripts/*.py`) using `subprocess.run` after the `AssetProcessor.process()` call completes successfully for an asset batch. See `Developer Guide: Blender Integration Internals` for more details.\n\\ No newline at end of file\n+    *   If triggered via CLI arguments (`--nodegroup-blend`, `--materials-blend`) or GUI controls, the orchestrator (`main.py` or `gui/processing_handler.py`) executes the corresponding Blender scripts (`blenderscripts/*.py`) using `subprocess.run` after the `AssetProcessor.process()` call completes successfully for an asset batch. See `Developer Guide: Blender Integration Internals` for more details.\r\n+\r\n+**Note on Data Passing:** As mentioned in the Architecture documentation, major changes to the data passing mechanisms between the GUI, Main (CLI orchestration), and `AssetProcessor` modules are currently being planned. The descriptions of how data is processed and transformed within this pipeline reflect the current state and will require review and updates once the plan for these changes is finalized.\n\\ No newline at end of file\n"
                }
            ],
            "date": 1745494656395,
            "name": "Commit-0",
            "content": "# Developer Guide: Processing Pipeline\r\n\r\nThis document details the step-by-step technical process executed by the `AssetProcessor` class (`asset_processor.py`) when processing a single asset.\r\n\r\nThe `AssetProcessor.process()` method orchestrates the following pipeline:\r\n\r\n1.  **Workspace Setup (`_setup_workspace`)**:\r\n    *   Creates a temporary directory using `tempfile.mkdtemp()` to isolate the processing of the current asset.\r\n\r\n2.  **Input Extraction (`_extract_input`)**:\r\n    *   If the input is a ZIP archive, it's extracted into the temporary workspace.\r\n    *   If the input is a directory, its contents are copied into the temporary workspace.\r\n\r\n3.  **File Inventory and Classification (`_inventory_and_classify_files`)**:\r\n    *   Scans the contents of the temporary workspace.\r\n    *   Uses the pre-compiled regex patterns from the loaded `Configuration` object to classify each file.\r\n    *   Classification follows a multi-pass approach for priority:\r\n        *   Explicitly marked `Extra/` files (using `move_to_extra_patterns` regex).\r\n        *   Model files (using `model_patterns` regex).\r\n        *   Potential Texture Maps (matching `map_type_mapping` keyword patterns).\r\n        *   Standalone 16-bit variants check (using `bit_depth_variants` patterns).\r\n        *   Prioritization of 16-bit variants over their 8-bit counterparts (marking the 8-bit version as `Ignored`).\r\n        *   Final classification of remaining potential maps.\r\n        *   Remaining files are classified as `Unrecognised` (and typically moved to `Extra/` later).\r\n    *   Stores the classification results (including source path, determined map type, potential variant suffix, etc.) in `self.classified_files`.\r\n    *   Sorts potential map variants based on preset rule order, keyword order within the rule, and finally alphabetical path to determine suffix assignment priority (`-1`, `-2`, etc.).\r\n\r\n4.  **Base Metadata Determination (`_determine_base_metadata`, `_determine_single_asset_metadata`)**:\r\n    *   Determines the base asset name using `source_naming_convention` rules from the `Configuration` (separators, indices), with fallbacks to common prefixes or the input name. Handles multiple distinct assets within a single input source.\r\n    *   Determines the asset category (`Texture`, `Asset`, `Decal`) based on the presence of model files or `decal_keywords` in the `Configuration`.\r\n    *   Determines the asset archetype (e.g., `Wood`, `Metal`) by matching keywords from `archetype_rules` (in `Configuration`) against file stems or the determined base name.\r\n    *   Stores this preliminary metadata.\r\n\r\n5.  **Skip Check**:\r\n    *   If the `overwrite` flag (passed during initialization) is `False`, the tool checks if the final output directory for the determined asset name already exists and contains a `metadata.json` file.\r\n    *   If both exist, processing for this specific asset is skipped, marked as \"skipped\", and the pipeline moves to the next asset (if processing multiple assets from one source) or finishes.\r\n\r\n6.  **Map Processing (`_process_maps`)**:\r\n    *   Iterates through the files classified as texture maps for the current asset.\r\n    *   Loads the image using `cv2.imread` (handling grayscale and unchanged flags). Converts BGR to RGB internally for consistency (except for saving non-EXR formats).\r\n    *   Handles Glossiness-to-Roughness inversion if necessary (loads gloss, inverts `1.0 - img/norm`, prioritizes gloss source if both exist).\r\n    *   Resizes the image to target resolutions defined in `IMAGE_RESOULTIONS` (from `Configuration`) using `cv2.resize` (`INTER_LANCZOS4` for downscaling). Upscaling is generally avoided by checks.\r\n    *   Determines the output bit depth based on `MAP_BIT_DEPTH_RULES` (`respect` vs `force_8bit`).\r\n    *   Determines the output file format (`.jpg`, `.png`, `.exr`) based on a hierarchy of rules:\r\n        *   `FORCE_LOSSLESS_MAP_TYPES` list (overrides other logic).\r\n        *   `RESOLUTION_THRESHOLD_FOR_JPG` (forces JPG for large 8-bit maps).\r\n        *   Source format, target bit depth, and configured defaults (`OUTPUT_FORMAT_16BIT_PRIMARY`, `OUTPUT_FORMAT_8BIT`).\r\n    *   Converts the NumPy array data type appropriately before saving (e.g., float to uint8/uint16 with scaling).\r\n    *   Saves the processed map using `cv2.imwrite` (converting RGB back to BGR if saving to non-EXR formats). Includes fallback logic (e.g., attempting PNG if saving 16-bit EXR fails).\r\n    *   Calculates image statistics (Min/Max/Mean) using `_calculate_image_stats` on normalized float64 data for the `CALCULATE_STATS_RESOLUTION`.\r\n    *   Determines the aspect ratio change string (e.g., `\"EVEN\"`, `\"X150\"`) using `_normalize_aspect_ratio_change`.\r\n    *   Stores details about each processed map (path, resolution, format, stats, etc.) in `processed_maps_details_asset`.\r\n\r\n7.  **Map Merging (`_merge_maps_from_source`)**:\r\n    *   Iterates through the `MAP_MERGE_RULES` defined in the `Configuration`.\r\n    *   Identifies the required *source* map files needed as input for each merge rule based on the classified files.\r\n    *   Determines common resolutions available across the required input maps.\r\n    *   Loads the necessary source map channels for each common resolution (using a helper `_load_and_transform_source` which includes caching).\r\n    *   Converts inputs to normalized float32 (0-1).\r\n    *   Injects default channel values (from rule `defaults`) if an input channel is missing.\r\n    *   Merges channels using `cv2.merge`.\r\n    *   Determines output bit depth and format based on rules (similar logic to `_process_maps`, considering input properties). Handles potential JPG 16-bit conflict by forcing 8-bit.\r\n    *   Saves the merged map using the `_save_image` helper (includes data type/color space conversions and fallback).\r\n    *   Stores details about each merged map in `merged_maps_details_asset`.\r\n\r\n8.  **Metadata File Generation (`_generate_metadata_file`)**:\r\n    *   Collects all determined information for the current asset: base metadata, details from `processed_maps_details_asset` and `merged_maps_details_asset`, list of ignored files, source preset used, etc.\r\n    *   Writes this collected data into the `metadata.json` file within the temporary workspace using `json.dump`.\r\n\r\n9.  **Output Organization (`_organize_output_files`)**:\r\n    *   Creates the final structured output directory: `<output_base_dir>/<supplier_name>/<asset_name>/`.\r\n    *   Creates subdirectories `Extra/`, `Unrecognised/`, and `Ignored/` within the asset directory.\r\n    *   Moves the processed maps, merged maps, model files, `metadata.json`, and files classified as Extra, Unrecognised, or Ignored from the temporary workspace into their respective locations in the final output directory structure.\r\n\r\n10. **Workspace Cleanup (`_cleanup_workspace`)**:\r\n    *   Removes the temporary workspace directory and its contents using `shutil.rmtree()`. This is called within a `finally` block to ensure cleanup is attempted even if errors occur during processing.\r\n\r\n11. **(Optional) Blender Script Execution**:\r\n    *   If triggered via CLI arguments (`--nodegroup-blend`, `--materials-blend`) or GUI controls, the orchestrator (`main.py` or `gui/processing_handler.py`) executes the corresponding Blender scripts (`blenderscripts/*.py`) using `subprocess.run` after the `AssetProcessor.process()` call completes successfully for an asset batch. See `Developer Guide: Blender Integration Internals` for more details."
        }
    ]
}