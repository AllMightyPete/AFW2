{
    "sourceFile": "llm_prototype/config_llm.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 16,
            "patches": [
                {
                    "date": 1745578435138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1745578838036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,70 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n+\r\n+# Path to the prompt template file\r\n+PROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"MET\", \"AO\", \"DISP\", \"SPEC\", \"GLOSS\",\r\n+    \"OPAC\", \"MASK\", \"SSS\", \"TRANSMISSION\", \"SHEEN\",\r\n+    \"COAT\", \"ANISO\", \"CLEARCOAT\", \"EMISSION\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745578901554,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,68 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n+\r\n+# Path to the prompt template file\r\n+PROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745579088430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,10 +12,10 @@\n \r\n # Environment variable name for the API key (if required by the API)\r\n LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n \r\n-# Path to the prompt template file\r\n-PROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n \r\n # Expected internal map types the LLM should classify files into\r\n EXPECTED_MAP_TYPES = [\r\n     \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n@@ -64,145 +64,5 @@\n     ]\r\n   }\r\n   // ... potentially more asset objects if more are detected\r\n ]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n-\r\n-# Path to the prompt template file\r\n-PROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"MET\", \"AO\", \"DISP\", \"SPEC\", \"GLOSS\",\r\n-    \"OPAC\", \"MASK\", \"SSS\", \"TRANSMISSION\", \"SHEEN\",\r\n-    \"COAT\", \"ANISO\", \"CLEARCOAT\", \"EMISSION\"\r\n-]\r\n-\r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n-]\r\n-\r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n-\r\n-# Path to the prompt template file\r\n-PROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"MET\", \"AO\", \"DISP\", \"SPEC\", \"GLOSS\",\r\n-    \"OPAC\", \"MASK\", \"SSS\", \"THICKNESS\", \"TRANSMISSION\", \"SHEEN\",\r\n-    \"COAT\", \"ANISO\", \"CLEARCOAT\", \"EMISSION\", \"HEIGHT\"\r\n-]\r\n-\r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"ATLAS\", \"Imperfection\"\r\n-]\r\n-\r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n-    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n \"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745579192519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,68 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n+\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745579787931,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,9 +7,9 @@\n # Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n \r\n # Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n \r\n # Environment variable name for the API key (if required by the API)\r\n LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n \r\n"
                },
                {
                    "date": 1745579811816,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n # Optional: LLM Model Name (may be required by some APIs)\r\n LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n \r\n # Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n+LLM_API_KEY_ENV_VAR = \"\"\r\n \r\n # Path to the prompt template file (relative to the workspace root)\r\n PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n \r\n@@ -64,73 +64,5 @@\n     ]\r\n   }\r\n   // ... potentially more asset objects if more are detected\r\n ]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n-\r\n-# Path to the prompt template file (relative to the workspace root)\r\n-PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n-]\r\n-\r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n-]\r\n-\r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n \"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745581873981,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n ]\r\n \r\n # Expected classifications for individual files\r\n EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n ]\r\n \r\n # Placeholder for the input file list in the prompt template\r\n FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n"
                },
                {
                    "date": 1745581959178,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n ]\r\n \r\n # Expected classifications for individual files\r\n EXPECTED_CLASSIFICATIONS = [\r\n-    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n ]\r\n \r\n # Placeholder for the input file list in the prompt template\r\n FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n"
                },
                {
                    "date": 1745582486512,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n ]\r\n \r\n # Expected classifications for individual files\r\n EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n ]\r\n \r\n # Placeholder for the input file list in the prompt template\r\n FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n"
                },
                {
                    "date": 1745582776559,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,68 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"\"\r\n+\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745582796782,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,68 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"\"\r\n+\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745583953234,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,68 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"\"\r\n+\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+]\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1745585696898,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,222 +17,32 @@\n PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n \r\n # Expected internal map types the LLM should classify files into\r\n EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\", \"utility\"\r\n ]\r\n \r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n-]\r\n+# Examples/synonyms for each map type to guide the LLM\r\n+MAP_TYPE_EXAMPLES = {\r\n+    \"COL\": [\"Color\", \"Diffuse\", \"Albedo\"],\r\n+    \"NRM\": [\"Normal\"],\r\n+    \"ROUGH\": [\"Roughness\"],\r\n+    \"METAL\": [\"Metallic\"],\r\n+    \"AO\": [\"Ambient Occlusion\"],\r\n+    \"DISP\": [\"Displacement\", \"Height\"],\r\n+    \"REFL\": [\"Reflection\"],\r\n+    \"MASK\": [\"Mask\", \"Alpha\", \"Opacity\"],\r\n+    \"SSS\": [\"Subsurface Scattering\"],\r\n+    \"utility\": [\"Utility\", \"Data\", \"Helper\"]\r\n+}\r\n \r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n-    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"\"\r\n-\r\n-# Path to the prompt template file (relative to the workspace root)\r\n-PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n-]\r\n-\r\n # Expected asset categories the LLM should classify assets into\r\n EXPECTED_CATEGORIES = [\r\n     \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n ]\r\n \r\n # Expected classifications for individual files\r\n EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"\"\r\n-\r\n-# Path to the prompt template file (relative to the workspace root)\r\n-PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n-]\r\n-\r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n-]\r\n-\r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n-    \"PBRMap\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n-]\r\n-\r\n-# Placeholder for the input file list in the prompt template\r\n-FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n-\r\n-# Placeholder for the expected map types list in the prompt template\r\n-MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n-\r\n-# Placeholder for the expected categories list in the prompt template\r\n-CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n-\r\n-# Placeholder for the expected classifications list in the prompt template\r\n-CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n-\r\n-# Placeholder for the expected JSON output schema in the prompt template\r\n-OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n-\r\n-# The expected JSON output schema structure (used for validation and prompt)\r\n-# This defines the structure the LLM should return AFTER the <thinking> block\r\n-OUTPUT_SCHEMA = \"\"\"\r\n-[ // Top-level LIST of assets\r\n-  { // Asset Object\r\n-    \"asset_name\": \"...\", // Determined name for the asset set\r\n-    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n-    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n-    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n-      {\r\n-        \"input_path\": \"...\", // The original path from the input list\r\n-        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n-        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n-      }\r\n-      // ... one entry for each file belonging to this asset\r\n-    ]\r\n-  }\r\n-  // ... potentially more asset objects if more are detected\r\n-]\r\n-\"\"\"\n-# llm_prototype/config_llm.py\r\n-\r\n-# Configuration for the LLM Asset Classifier Prototype\r\n-\r\n-# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n-# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n-# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n-LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n-\r\n-# Optional: LLM Model Name (may be required by some APIs)\r\n-LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n-\r\n-# Environment variable name for the API key (if required by the API)\r\n-LLM_API_KEY_ENV_VAR = \"\"\r\n-\r\n-# Path to the prompt template file (relative to the workspace root)\r\n-PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n-\r\n-# Expected internal map types the LLM should classify files into\r\n-EXPECTED_MAP_TYPES = [\r\n-    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\"\r\n-]\r\n-\r\n-# Expected asset categories the LLM should classify assets into\r\n-EXPECTED_CATEGORIES = [\r\n-    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n-]\r\n-\r\n-# Expected classifications for individual files\r\n-EXPECTED_CLASSIFICATIONS = [\r\n     \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n ]\r\n \r\n # Placeholder for the input file list in the prompt template\r\n"
                },
                {
                    "date": 1745586033628,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,9 +31,9 @@\n     \"DISP\": [\"Displacement\", \"Height\"],\r\n     \"REFL\": [\"Reflection\"],\r\n     \"MASK\": [\"Mask\", \"Alpha\", \"Opacity\"],\r\n     \"SSS\": [\"Subsurface Scattering\"],\r\n-    \"utility\": [\"Utility\", \"Data\", \"Helper\"]\r\n+    \"UTILITY\": [\"Imperfection\", \"Scratch\", \"Fuzz\"]\r\n }\r\n \r\n # Expected asset categories the LLM should classify assets into\r\n EXPECTED_CATEGORIES = [\r\n"
                },
                {
                    "date": 1745586108492,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,16 +31,25 @@\n     \"DISP\": [\"Displacement\", \"Height\"],\r\n     \"REFL\": [\"Reflection\"],\r\n     \"MASK\": [\"Mask\", \"Alpha\", \"Opacity\"],\r\n     \"SSS\": [\"Subsurface Scattering\"],\r\n-    \"UTILITY\": [\"Imperfection\", \"Scratch\", \"Fuzz\"]\r\n+    \"utility\": [\"Utility\", \"Data\", \"Helper\"]\r\n }\r\n \r\n # Expected asset categories the LLM should classify assets into\r\n EXPECTED_CATEGORIES = [\r\n     \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n ]\r\n \r\n+# Examples/synonyms for each asset category to guide the LLM\r\n+CATEGORY_EXAMPLES = {\r\n+    \"Model\": \"Represents a 3D mesh or object file (e.g., .obj, .fbx, .gltf).\",\r\n+    \"Surface\": \"Represents a set of textures intended for a material (e.g., PBR texture sets with Color, Normal, Roughness maps).\",\r\n+    \"Decal\": \"Represents a texture or set of textures intended to be placed on top of another material (e.g., stickers, grunge overlays).\",\r\n+    \"Atlas\": \"Represents a single texture file containing multiple smaller textures or sprites.\",\r\n+    \"Imperfection\": \"Represents textures used to add surface imperfections like smudges, scratches, or dust. Typically single-channel maps.\"\r\n+}\r\n+\r\n # Expected classifications for individual files\r\n EXPECTED_CLASSIFICATIONS = [\r\n     \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n ]\r\n@@ -53,8 +62,11 @@\n \r\n # Placeholder for the expected categories list in the prompt template\r\n CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n \r\n+# Placeholder for the category examples in the prompt template\r\n+CATEGORY_EXAMPLES_PLACEHOLDER = \"{{CATEGORY_EXAMPLES}}\"\r\n+\r\n # Placeholder for the expected classifications list in the prompt template\r\n CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n \r\n # Placeholder for the expected JSON output schema in the prompt template\r\n"
                },
                {
                    "date": 1745586537796,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,94 @@\n+# llm_prototype/config_llm.py\r\n+\r\n+# Configuration for the LLM Asset Classifier Prototype\r\n+\r\n+# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n+# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n+# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\n+LLM_API_ENDPOINT = \"http://100.65.14.122:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n+\r\n+# Optional: LLM Model Name (may be required by some APIs)\r\n+LLM_MODEL_NAME = \"phi-3.5-mini-instruct\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n+\r\n+# Environment variable name for the API key (if required by the API)\r\n+LLM_API_KEY_ENV_VAR = \"\"\r\n+\r\n+# Path to the prompt template file (relative to the workspace root)\r\n+PROMPT_TEMPLATE_PATH = \"llm_prototype/prompt_template.txt\"\r\n+\r\n+# Expected internal map types the LLM should classify files into\r\n+EXPECTED_MAP_TYPES = [\r\n+    \"COL\", \"NRM\", \"ROUGH\", \"METAL\", \"AO\", \"DISP\", \"REFL\", \"MASK\", \"SSS\", \"utility\"\r\n+]\r\n+\r\n+# Examples/synonyms for each map type to guide the LLM\r\n+MAP_TYPE_EXAMPLES = {\r\n+    \"COL\": [\"Color\", \"Diffuse\", \"Albedo\"],\r\n+    \"NRM\": [\"Normal\"],\r\n+    \"ROUGH\": [\"Roughness\"],\r\n+    \"METAL\": [\"Metallic\"],\r\n+    \"AO\": [\"Ambient Occlusion\"],\r\n+    \"DISP\": [\"Displacement\", \"Height\"],\r\n+    \"REFL\": [\"Reflection\"],\r\n+    \"MASK\": [\"Mask\", \"Alpha\", \"Opacity\"],\r\n+    \"SSS\": [\"Subsurface Scattering\"],\r\n+    \"utility\": [\"Utility\", \"Data\", \"Helper\"]\r\n+}\r\n+\r\n+# Expected asset categories the LLM should classify assets into\r\n+EXPECTED_CATEGORIES = [\r\n+    \"Model\", \"Surface\", \"Decal\", \"Atlas\", \"Imperfection\"\r\n+]\r\n+\r\n+# Examples/synonyms for each asset category to guide the LLM\r\n+CATEGORY_EXAMPLES = {\r\n+    \"Model\": \"Represents a asset-set that has a 3D file (e.g., .obj, .fbx, .gltf). Can include accompanying PBR maps as well\",\r\n+    \"Surface\": \"Represents a set of textures intended for a material (e.g., PBR texture sets with Color, Normal, Roughness maps).\",\r\n+    \"Decal\": \"Represents a texture or set of textures intended to be placed on top of another material (e.g., stickers, grunge overlays). Always has some form of a opacity or mask map\",\r\n+    \"Atlas\": \"Represents a texture or set of textures. Often called atlas or trimsheet\",\r\n+    \"Imperfection\": \"Represents a single texturemap used to add surface imperfections\"\r\n+    }\r\n+\r\n+# Expected classifications for individual files\r\n+EXPECTED_CLASSIFICATIONS = [\r\n+    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n+]\r\n+\r\n+# Placeholder for the input file list in the prompt template\r\n+FILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n+\r\n+# Placeholder for the expected map types list in the prompt template\r\n+MAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n+\r\n+# Placeholder for the expected categories list in the prompt template\r\n+CATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n+\r\n+# Placeholder for the category examples in the prompt template\r\n+CATEGORY_EXAMPLES_PLACEHOLDER = \"{{CATEGORY_EXAMPLES}}\"\r\n+\r\n+# Placeholder for the expected classifications list in the prompt template\r\n+CLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n+\r\n+# Placeholder for the expected JSON output schema in the prompt template\r\n+OUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n+\r\n+# The expected JSON output schema structure (used for validation and prompt)\r\n+# This defines the structure the LLM should return AFTER the <thinking> block\r\n+OUTPUT_SCHEMA = \"\"\"\r\n+[ // Top-level LIST of assets\r\n+  { // Asset Object\r\n+    \"asset_name\": \"...\", // Determined name for the asset set\r\n+    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n+    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n+    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n+      {\r\n+        \"input_path\": \"...\", // The original path from the input list\r\n+        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n+        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n+      }\r\n+      // ... one entry for each file belonging to this asset\r\n+    ]\r\n+  }\r\n+  // ... potentially more asset objects if more are detected\r\n+]\r\n+\"\"\"\n\\ No newline at end of file\n"
                }
            ],
            "date": 1745578435138,
            "name": "Commit-0",
            "content": "# llm_prototype/config_llm.py\r\n\r\n# Configuration for the LLM Asset Classifier Prototype\r\n\r\n# LLM API Endpoint (e.g., for OpenAI, local LLM via LM Studio, etc.)\r\n# Example for OpenAI: \"https://api.openai.com/v1/chat/completions\"\r\n# Example for LM Studio: \"http://localhost:1234/v1/chat/completions\"\r\nLLM_API_ENDPOINT = \"http://localhost:1234/v1/chat/completions\" # Default to local LM Studio endpoint\r\n\r\n# Optional: LLM Model Name (may be required by some APIs)\r\nLLM_MODEL_NAME = \"\" # e.g., \"gpt-4o-mini\", \"llama-3-8b-instruct\"\r\n\r\n# Environment variable name for the API key (if required by the API)\r\nLLM_API_KEY_ENV_VAR = \"OPENAI_API_KEY\"\r\n\r\n# Path to the prompt template file\r\nPROMPT_TEMPLATE_PATH = \"prompt_template.txt\"\r\n\r\n# Expected internal map types the LLM should classify files into\r\nEXPECTED_MAP_TYPES = [\r\n    \"COL\", \"NRM\", \"ROUGH\", \"MET\", \"AO\", \"DISP\", \"SPEC\", \"GLOSS\",\r\n    \"OPAC\", \"MASK\", \"SSS\", \"THICKNESS\", \"TRANSMISSION\", \"SHEEN\",\r\n    \"COAT\", \"ANISO\", \"CLEARCOAT\", \"EMISSION\", \"HEIGHT\"\r\n]\r\n\r\n# Expected asset categories the LLM should classify assets into\r\nEXPECTED_CATEGORIES = [\r\n    \"Model\", \"Surface\", \"Decal\", \"ATLAS\", \"Imperfection\"\r\n]\r\n\r\n# Expected classifications for individual files\r\nEXPECTED_CLASSIFICATIONS = [\r\n    \"Map\", \"Model\", \"Extra\", \"Ignored\", \"Unrecognised\"\r\n]\r\n\r\n# Placeholder for the input file list in the prompt template\r\nFILE_LIST_PLACEHOLDER = \"{{FILE_LIST_JSON}}\"\r\n\r\n# Placeholder for the expected map types list in the prompt template\r\nMAP_TYPES_PLACEHOLDER = \"{{EXPECTED_MAP_TYPES}}\"\r\n\r\n# Placeholder for the expected categories list in the prompt template\r\nCATEGORIES_PLACEHOLDER = \"{{EXPECTED_CATEGORIES}}\"\r\n\r\n# Placeholder for the expected classifications list in the prompt template\r\nCLASSIFICATIONS_PLACEHOLDER = \"{{EXPECTED_CLASSIFICATIONS}}\"\r\n\r\n# Placeholder for the expected JSON output schema in the prompt template\r\nOUTPUT_SCHEMA_PLACEHOLDER = \"{{OUTPUT_SCHEMA}}\"\r\n\r\n# The expected JSON output schema structure (used for validation and prompt)\r\n# This defines the structure the LLM should return AFTER the <thinking> block\r\nOUTPUT_SCHEMA = \"\"\"\r\n[ // Top-level LIST of assets\r\n  { // Asset Object\r\n    \"asset_name\": \"...\", // Determined name for the asset set\r\n    \"asset_category\": \"...\", // Must be one of: {{CATEGORIES_PLACEHOLDER}}\r\n    \"asset_archetype\": \"...\", // e.g., Wood, Metal, Fabric, Concrete, Smudge, Scratch, etc.\r\n    \"file_classifications\": [ // List of files belonging ONLY to this asset\r\n      {\r\n        \"input_path\": \"...\", // The original path from the input list\r\n        \"classification\": \"...\", // Must be one of: {{CLASSIFICATIONS_PLACEHOLDER}}\r\n        \"map_type\": \"...\" // Must be one of: {{MAP_TYPES_PLACEHOLDER}}, or null if not a Map\r\n      }\r\n      // ... one entry for each file belonging to this asset\r\n    ]\r\n  }\r\n  // ... potentially more asset objects if more are detected\r\n]\r\n\"\"\""
        }
    ]
}