{
    "sourceFile": "llm_prototype/PLAN.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1745578414378,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1745578414378,
            "name": "Commit-0",
            "content": "# LLM Asset Classifier Prototype Plan\r\n\r\n## 1. Goal\r\n\r\nDevelop a standalone Python prototype module capable of classifying 3D asset files and determining relevant metadata by leveraging a Large Language Model (LLM). This prototype aims to:\r\n\r\n*   Handle irregularly named input files where traditional regex/keyword-based presets fail.\r\n*   Support inputs containing multiple distinct assets within a single source directory or archive.\r\n*   Provide a flexible foundation for potential future integration into the main Asset Processor Tool.\r\n\r\n## 2. Approach\r\n\r\nWe will adopt the following strategies for the prototype development:\r\n\r\n*   **Standalone Prototype:** The core LLM interaction and classification logic will be built within a dedicated `llm_prototype/` directory. This isolates development, allows for focused testing, and de-risks the feature before considering integration into the main application.\r\n*   **Configurable LLM Endpoint:** The prototype will allow users to specify the LLM API endpoint via a configuration file (`config_llm.py`). This enables flexibility in using different LLM providers, including locally hosted models (e.g., via LM Studio) or commercial APIs. API keys will be managed securely via environment variables, not stored in configuration files.\r\n*   **Multi-Asset Handling via List Output:** To address inputs containing multiple assets (e.g., `Dinesen.zip`, `DG_Imperfections.zip`), the LLM will be prompted to return its findings as a JSON **list**. Each element in the list will represent a single, distinct asset identified within the input file set.\r\n*   **Chain of Thought (CoT) Prompting:** We will employ a Chain of Thought prompting technique. The LLM will be instructed first to outline its reasoning process (identifying asset groups, assigning files, determining metadata) within `<thinking>` tags before generating the final, structured JSON output. This aims to improve the reliability and accuracy of handling the complex multi-asset identification task.\r\n*   **Unified Asset Category:** A single `asset_category` field will be used to classify the type of asset. The defined valid categories are: `Model`, `Surface`, `Decal`, `ATLAS`, `Imperfection`.\r\n*   **JSON Extraction & Validation:** The Python script (`llm_classifier.py`) will parse the full LLM response, extract the JSON list portion following the `<thinking>` block, and perform strict validation against the expected schema and defined category/map type values.\r\n*   **Minimal Dependencies:** The prototype will aim for minimal external dependencies, primarily using the `requests` library for API communication.\r\n\r\n## 3. Prototype Structure (`llm_prototype/`)\r\n\r\n*   `llm_classifier.py`: Main Python script containing the core logic for loading input, formatting prompts, calling the LLM, parsing the response, and validating the output.\r\n*   `config_llm.py`: Configuration file defining the LLM API endpoint, expected map types, expected asset categories, and the path to the prompt template.\r\n*   `requirements_llm.txt`: Lists Python dependencies (e.g., `requests`).\r\n*   `prompt_template.txt`: Text file containing the Chain of Thought prompt template with placeholders for input files and configuration values.\r\n*   `test_inputs/`: Directory containing example input file lists in JSON format (e.g., `test_inputs/dinesen_example.json`, `test_inputs/imperfections_example.json`).\r\n*   `README.md`: Instructions detailing setup, configuration (API endpoint, environment variables), and how to run the prototype.\r\n\r\n## 4. Key Schemas\r\n\r\n*   **Input to Prototype (Example - `test_inputs/dinesen_example.json`):**\r\n    ```json\r\n    {\r\n      \"files\": [\r\n        \"3-HeartOak-RL-2-5m-300mm_COL-1_.jpg\",\r\n        \"3-HeartOak-RL-2-5m-300mm_DISP_.jpg\",\r\n        \"3-HeartOak-RL-2-5m-300mm_GLOSS_.jpg\",\r\n        \"3-HeartOak-RL-2-5m-300mm_NRM_.jpg\",\r\n        \"3-Oak-Classic-RL-2-5m-300mm_COL-1_.jpg\",\r\n        \"3-Oak-Classic-RL-2-5m-300mm_DISP_.jpg\",\r\n        \"3-Oak-Classic-RL-2-5m-300mm_GLOSS_.jpg\",\r\n        \"3-Oak-Classic-RL-2-5m-300mm_NRM_.jpg\"\r\n      ]\r\n    }\r\n    ```\r\n*   **Expected LLM Output (Conceptual Structure):**\r\n    ```json\r\n    [\r\n      {\r\n        \"asset_name\": \"3-HeartOak-RL-2-5m-300mm\",\r\n        \"asset_category\": \"Surface\", // Unified: Model, Surface, Decal, ATLAS, Imperfection\r\n        \"asset_archetype\": \"Wood\",\r\n        \"file_classifications\": [\r\n          {\"input_path\": \"3-HeartOak-RL-2-5m-300mm_COL-1_.jpg\", \"classification\": \"Map\", \"map_type\": \"COL\"},\r\n          // ... other HeartOak files\r\n        ]\r\n      },\r\n      {\r\n        \"asset_name\": \"3-Oak-Classic-RL-2-5m-300mm\",\r\n        \"asset_category\": \"Surface\",\r\n        \"asset_archetype\": \"Wood\",\r\n        \"file_classifications\": [\r\n           {\"input_path\": \"3-Oak-Classic-RL-2-5m-300mm_COL-1_.jpg\", \"classification\": \"Map\", \"map_type\": \"COL\"},\r\n           // ... other OakClassic files\r\n        ]\r\n      }\r\n    ]\r\n    ```\r\n\r\n## 5. Next Steps\r\n\r\n1.  Create the `llm_prototype/` directory structure. (Already exists, confirmed empty)\r\n2.  Create the initial placeholder files (`llm_classifier.py`, `config_llm.py`, `requirements_llm.txt`, `prompt_template.txt`, `README.md`).\r\n3.  Populate `config_llm.py` with initial configuration variables.\r\n4.  Draft the initial `prompt_template.txt`.\r\n5.  Create example input files in `test_inputs/`.\r\n6.  Begin implementing the core logic in `llm_classifier.py`."
        }
    ]
}